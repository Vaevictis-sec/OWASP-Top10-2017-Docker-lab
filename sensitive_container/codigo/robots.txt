#
# robots.txt
#
# This file is to prevent the crawling and indexing of certain parts
# of your site by web crawlers and spiders run by sites like Yahoo!
# and Google. By telling these "robots" where not to go on your site,
# you save bandwidth and server resources.
#
# This file will be ignored unless it is at the root of your host:
# Used:    http://example.com/robots.txt
# Ignored: http://example.com/site/robots.txt
#
# For more information about the robots.txt standard, see:
# http://www.robotstxt.org/robotstxt.html
#
# For syntax checking, see:
# http://www.frobee.com/robots-txt-check

User-agent: *
Crawl-delay: 10
# Directories
Disallow: /includes/
Disallow: /misc/
Disallow: /modules/
Disallow: /profiles/
Disallow: /scripts/
Disallow: /themes/
# Files
Disallow: /CHANGELOG.txt
Disallow: /cron.php
Disallow: /INSTALL.mysql.txt
Disallow: /INSTALL.pgsql.txt
Disallow: /INSTALL.sqlite.txt
Disallow: /install.php
Disallow: /INSTALL.txt
Disallow: /LICENSE.txt
Disallow: /MAINTAINERS.txt
Disallow: /update.php
Disallow: /UPGRADE.txt
Disallow: /xmlrpc.php
Disallow: /directoriosecreto/
# Paths (clean URLs)
Disallow: /admin/
Disallow: /comment/reply/
Disallow: /filter/tips/
Disallow: /node/add/
Disallow: /search/
Disallow: /user/register/
Disallow: /user/password/
Disallow: /user/login/
Disallow: /user/logout/
# Paths (no clean URLs)
Disallow: /?q=admin/
Disallow: /?q=comment/reply/
Disallow: /?q=filter/tips/
Disallow: /?q=node/add/
Disallow: /?q=search/
Disallow: /?q=user/password/
Disallow: /?q=user/register/
Disallow: /?q=user/login/
Disallow: /?q=user/logout/

User-agent: Mozilla/5.0 (compatible;picmole/1.0 +http://www.picmole.com)
Disallow: /

User-agent: LexxeBot/1.0
Disallow: /

User-agent: NextGenSearchBot
Disallow: /

User-agent: Mozilla/5.0 (compatible; spbot/2.0; http://www.seoprofiler.com/bot/ )
Disallow: /

User-agent: Sosospider
Disallow: /

User-agent: Sosospider+(+http://help.soso.com/webspider.htm)
Disallow: /

User-agent: SiteBot/0.1
Disallow: /

User-agent: SiteBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: crystalsemanticsbot
Disallow: /

User-agent: CrystalSemanticsBot
Disallow: /

User-agent: NetSeer crawler
Disallow: /

User-agent: trovitBot
Disallow: /

User-agent: LexxeBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: Ezooms
Disallow: /

User-agent: discobot
Disallow: /

User-agent: Jyxobot
Disallow: /

User-agent: sogou
Disallow: /

User-agent: sogou spider
Disallow: /

User-agent: Sogou web spider/4.0(+http://www.sogou.com/docs/help/webmasters.htm#07)
Disallow: /

User-agent: sistrix
Disallow: /

User-agent: heritrix
Disallow: /

User-agent: GarlikCrawler/1.1 (http://garlik.com/, crawler@garlik.com)
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: NerdByNature.Bot
Disallow: /

User-agent: Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt; DTS Agent
Disallow: /

User-agent: psbot
Disallow: /

User-agent: WBSearchBot
Disallow: /

User-agent: AddThis.com robot tech.support@clearspring.com
Disallow: /

User-agent: AddThis.com
Disallow: /

User-agent: ia_archiver
Disallow: /

User-agent: proximic
Disallow: /

User-agent: discoverybot
Disallow: /

User-agent: bl.uk_lddc_bot
Disallow: /

User-agent: IstellaBot
Disallow: /

User-agent: seokicks
Disallow: /

User-agent: SEOkicks-Robot
Disallow: /

User-agent: UnisterBot
Disallow: /

User-agent: Bender
Disallow: /

User-agent: wotbox
Disallow: /

User-agent: Yasni
Disallow: /

User-agent: JikeSpider
Disallow: /

User-agent: netEstate NE Crawler
Disallow: /

User-agent: Exabot
Disallow: /

User-agent: Pixray-Seeker
Disallow: /

User-agent: Linguee
Disallow: /

User-agent: integromedb
Disallow: /

User-agent: SearchmetricsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: BDCbot
Disallow: /

User-agent: GrapeshotCrawler
Disallow: /

User-agent: WeSEE:Search
Disallow: /

User-agent: TurnitinBot
Disallow: /

User-agent: admantx 
Disallow: /

User-agent: spbot
Disallow: /

User-agent: BUbiNG
Disallow: /
